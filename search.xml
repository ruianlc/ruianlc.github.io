<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>机器学习中如何应对非正态分布数据的建模</title>
      <link href="/2022/11/17/non-normal-distribution-and-non-parameter-models/"/>
      <url>/2022/11/17/non-normal-distribution-and-non-parameter-models/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在机器学习或数据分析过程中，通常会期待手里所拿到的数据在统计上是符合正态分布的。原因是大多常用的分析工具或算法模型均是以符合正态分布为前提条件。</p><p>比如，统计分析中的平均值、标准偏差、方差分析等；机器学习中的主成分分析、参数模型（如线性回归、判别分析等）。</p><p>当数据呈非正态分布时，计算平均值、标偏等就没有统计学意义；方差分析的过程涉及F检验，同样以样本服从正态分布为假设前提；当进行主成分降维时，每一个主成分都是方差最大化的方向，而计算方差本身的前提则是样本满足正态分布；而线性回归等模型要求残差服从正态分布，否则就无法计算模型参数的置信区间。</p><h2 id="正态分布-and-非正态分布"><a href="#正态分布-and-非正态分布" class="headerlink" title="正态分布 and 非正态分布"></a>正态分布 and 非正态分布</h2><p>对于做机器学习建模来说，最乐于看到的还是样本的特征呈正态分布，因此许多数据探索、特征工程以及模型本身都需要以服从正态分布为前提。</p><p>通常来说，我们期望的特征分布如下图所示：</p><p><img src="https://user-images.githubusercontent.com/114786693/202475769-83a3ed09-9bbe-4e59-bc22-6a175ca3582d.png" alt="image"></p><p>呈正态分布的效果是可以尝试更多的分析技巧和选用更多的模型。但实际上，可能碰到的数据特征分布是下面这种情况：</p><p><img src="https://user-images.githubusercontent.com/114786693/202490844-d4e099c9-7467-4a2b-ab41-49cebf21ea54.png" alt="image"><br>呈明显的偏态分布。</p><p>或者下面这种：<br><img src="https://user-images.githubusercontent.com/114786693/202484733-31eb4fb0-9843-473e-9120-e25d1c16cf79.png" alt="image"></p><p>分布出现两个甚至多个峰值，与标准的正态分布差别甚大。当出现多峰时，首先需要分析其原因。是否是因为存在多个不同的组？譬如在分类模型中，将所有不同类别的样本放在一起，那么特征分布出现多峰值就比较合理。</p><p>那么如果针对回归模型，或者分类模型中每个类别的特征分布仍呈非正态分布，这时应该如何处理呢？</p><p>大体来说，可采用两种不同的策略：</p><ul><li>对样本特征进行数据变换：如log变换、power transformation、quantile transformation等，这些都是将样本向正态分布方向进行变换的方式。一般来说，对于呈偏态分布采用log transformation、或者power transformation基本已足够将其转换为正态分布了。但对于呈多峰分布的，甚至需要通过分位数变换才能达到正态分布变换的效果。</li><li>采用非参数模型：每个模型都有其假设前提或者限制条件。尽管许多模型近能够从满足正态分布的数据集中完成学习，但仍有大量的模型可以直接针对非正态分布的数据集完成训练学习，如SVM、Random Forests、Decision Trees或者Gradient Boosted Trees等。</li></ul><p>到这里，基本讲完了如何在机器学习建模过程中如何应对非正态数据的处理了。那么什么是参数模型、或者非参数模型呢？</p><h2 id="参数模型-and-非参数模型"><a href="#参数模型-and-非参数模型" class="headerlink" title="参数模型 and 非参数模型"></a>参数模型 and 非参数模型</h2><p>参数模型中的模型参数数量固定，与数据集无关；在非参数模型中，参数的数量与样本集相关，参数数量会随着数据集增长而增加。</p><p>参数模型以数据分布为假设前提，从样本数据中估计模型参数（如均值、标偏等）用于建模，当数据分布呈偏态或者多峰分布时，均值则无法代表样本的总体情况，从而影响模型表现。非参模型不考虑特征分布，比如在决策树中，仅考虑两个分支的决策差异最大化，那么数据分布对于该过程则没有影响。</p><p>由于非参数模型，对于数据分布没有假设前提，因此可用于特征呈非正态分布的数据集建模。譬如在分类问题中，许多分类模型就可以直接处理非正态分布的特征数据集，如非参数模型支持向量机、决策树等，均可以处理非正态分布数据集。</p><p>下图是不同机器学习模型是否属于参数或非参数模型的汇总：<br><img src="https://user-images.githubusercontent.com/114786693/202493584-cec807b3-2875-4432-9b1e-b4f6ed4b8e6a.png" alt="Image"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文以非正态分布为说明入口，从以下几个方面论述开来：</p><ul><li>正态分布的意义；</li><li>非正态分布的表现和影响；</li><li>如何应对非正态分布；</li><li>非参数模型与参数模型的说明。</li></ul><p>Reference</p><p>[1] <a href="https://datascience.stackexchange.com/questions/25789/why-does-pca-assume-gaussian-distribution">https://datascience.stackexchange.com/questions/25789/why-does-pca-assume-gaussian-distribution</a></p><p>[2] <a href="https://www.quality-control-plan.com/StatGuide/ftest_ass_viol.htm">https://www.quality-control-plan.com/StatGuide/ftest_ass_viol.htm</a></p><p>[3] <a href="https://www.statology.org/multimodal-distribution/">https://www.statology.org/multimodal-distribution/</a></p><p>[4] <a href="https://stats.stackexchange.com/questions/268638/what-exactly-is-the-difference-between-a-parametric-and-non-parametric-model">https://stats.stackexchange.com/questions/268638/what-exactly-is-the-difference-between-a-parametric-and-non-parametric-model</a></p><p>[5] <a href="https://vitalflux.com/difference-between-parametric-vs-non-parametric-models/">https://vitalflux.com/difference-between-parametric-vs-non-parametric-models/</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法理论 </tag>
            
            <tag> 数据分布 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用numba对python数组复杂运算加速1000倍以上</title>
      <link href="/2022/11/12/use-numba-to-accelate-numpy-operation-by-more-than-thousands-times-faster/"/>
      <url>/2022/11/12/use-numba-to-accelate-numpy-operation-by-more-than-thousands-times-faster/</url>
      
        <content type="html"><![CDATA[<h2 id="numba介绍"><a href="#numba介绍" class="headerlink" title="numba介绍"></a>numba介绍</h2><p>Numba 是适用于 Python 的即时编译器（jit），最适用于使用 NumPy 数组和函数以及循环的代码。 使用 Numba 最常见的方法是通过它的装饰器集合，通过这些装饰器来标记函数使用 Numba 编译。 当调用 Numba 修饰函数时，它会“即时”编译为机器代码以供执行，最后使用 LLVM 编译器库生成函数的机器码，每次调用函数时都会使用此编译版本。</p><h2 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h2><p>在使用numba进行加速时，首先需要在待加速函数前添加<code>@git</code>装饰器，但这并不足够。因为numba中支持的数据类别和运算类型，和numpy不完全一致，具体可参考<a href="https://numba.pydata.org/numba-doc/0.24.0/reference/numpysupported.html">numba supported types</a>。</p><p>因此，一般情况下需要对原来的函数代码进行修改。涉及的修改情况，比如<code>list</code>类型，比如numpy运算<code>np.zeros()</code>等，需要将这些修改为numba中支持的类型。只有添加了jit编译装饰器，并且将代码完全修改为numba所支持的类型和运算，那么通过numba加速才能实现。</p><p>下面是列的一个numba加速的参考示例，对于数据类型和运算均有进行相应修改匹配，使其符合numba。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> numba<span class="token punctuation">.</span>typed <span class="token keyword">import</span> List<span class="token decorator annotation punctuation">@jit</span><span class="token punctuation">(</span>nopython<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> parallel<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">my_fun</span><span class="token punctuation">(</span>ary_data<span class="token punctuation">,</span> nums <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">,</span> ab_ratio<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    rows <span class="token operator">=</span> ary_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    stmp <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>rows<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        r_num <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>rows <span class="token operator">*</span> ab_ratio<span class="token punctuation">)</span>        ind <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>rows<span class="token punctuation">)</span>        index <span class="token operator">=</span> ind<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>r_num<span class="token punctuation">]</span>          val <span class="token operator">=</span> ary_data<span class="token punctuation">[</span>index<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>                       val_mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>val<span class="token punctuation">)</span>         val_std <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>val<span class="token punctuation">)</span>                        tt <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>rows<span class="token punctuation">)</span><span class="token punctuation">:</span>            rr <span class="token operator">=</span> <span class="token punctuation">(</span>ary_data<span class="token punctuation">[</span>j<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> val_mean<span class="token punctuation">)</span> <span class="token operator">/</span> val_std            tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>rr<span class="token punctuation">)</span>            tt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>tt<span class="token punctuation">)</span><span class="token decorator annotation punctuation">@jit</span><span class="token punctuation">(</span>nopython<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> parallel<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">use_fun</span><span class="token punctuation">(</span>data_src<span class="token punctuation">,</span> class_num<span class="token punctuation">,</span> nums <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">,</span> ab_ratio<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    inds_final <span class="token operator">=</span> List<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> cc <span class="token keyword">in</span> prange<span class="token punctuation">(</span>class_num<span class="token punctuation">)</span><span class="token punctuation">:</span>        inds_level <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>data_src<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span>cc<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        data_level <span class="token operator">=</span> data_src<span class="token punctuation">[</span>inds_level<span class="token punctuation">]</span>        selectIdx <span class="token operator">=</span> my_fun<span class="token punctuation">(</span>data_level<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> ab_ratio<span class="token punctuation">)</span>        resIdx <span class="token operator">=</span> <span class="token punctuation">[</span>inds_level<span class="token punctuation">[</span>v<span class="token punctuation">]</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> selectIdx<span class="token punctuation">]</span>        inds_final<span class="token punctuation">.</span>append<span class="token punctuation">(</span>resIdx<span class="token punctuation">)</span>       <span class="token keyword">return</span> inds_finaldf_data_use <span class="token operator">=</span> df<span class="token punctuation">[</span>names<span class="token operator">+</span><span class="token punctuation">[</span>target<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesinds_select <span class="token operator">=</span> use_fun<span class="token punctuation">(</span>df_data_use<span class="token punctuation">,</span> labes_nums<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过numba加速后，的确是发现它的强大威力。之前40万个样本用两轮的数据处理逻辑，就需要1个小时。借助于numba加速，全部样本执行100轮不到1分钟就可完成。加速效果好比是从小电动直接升级为火箭！</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在python加速方面，主要是三个不同方向：</p><ul><li>python向量化编程：这在前面的文章中已有相关总结<a href="https://ruianlc.github.io/2022/11/02/how-i-improve-pandas-operation-500x-faster/">refer</a></li><li>cython：python调用c&#x2F;c++代码，需要对c&#x2F;c++编程熟悉</li><li>numba：通过jit编译器，将python代码编译为llvm字节码</li></ul><p>一般来说，在python开发特别时科学计算时，向量化编程是必须采用的，既可提高代码执行效率，也使得代码更加简洁；cython应用于某些模块需要用c&#x2F;c++开发实现提速的场景；当涉及numpy数组操作，包含较多的for循环时，一定得考虑用numba加速，在解决特别大的数组上，威力巨大。</p><p>Reference</p><p>[1] <a href="https://numba.pydata.org/numba-doc/latest/user/5minguide.html/">https://numba.pydata.org/numba-doc/latest/user/5minguide.html\</a><br>[2] <a href="http://stephanhoyer.com/2015/04/09/numba-vs-cython-how-to-choose/">http://stephanhoyer.com/2015/04/09/numba-vs-cython-how-to-choose/</a></p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> numpy </tag>
            
            <tag> numba </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何使用pandas实现对40万样本集的快速运算</title>
      <link href="/2022/11/02/how-i-improve-pandas-operation-500x-faster/"/>
      <url>/2022/11/02/how-i-improve-pandas-operation-500x-faster/</url>
      
        <content type="html"><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>近期在项目中，涉及到对大样本、高维数据集的分析建模，总体上样本数量有40万个，特征维度有近300个。整个分析建模采用python机器学习框架，涉及pandas进行数据清洗，其中需要依据判断条件对异常样本进行剔除。当在小样本情况下，无论多复杂的处理逻辑，对pandas操作基本都会很快，但当样本变得庞大以后，对于速度的要求则会变得逐渐突出。</p><p>运算逻辑是能够定位到近300个特征中，任意一个特征出现异常数值范围的样本索引。比如正常值处于(0,1)之间，超出此范围的视为异常值。</p><p>本文从以下三个方式来说明加速pandas运算的一些技巧：</p><ul><li><code>for loop</code>进行pandas运算；</li><li>通过间接列扩增实现pandas运算；</li><li>采用pandas本身算子完成pandas运算。</li></ul><h2 id="for-loop形式的pandas运算"><a href="#for-loop形式的pandas运算" class="headerlink" title="for loop形式的pandas运算"></a><code>for loop</code>形式的pandas运算</h2><p>这是新手容易产生的最直接做法，通过遍历读取逐行样本，若该行的最小值小于0或者最大值的大于1，则该行即为异常样本。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">drop_abnormal_val</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>ab_idxs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>singsmaple <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>ii<span class="token punctuation">,</span> spc_names<span class="token punctuation">]</span><span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token builtin">min</span><span class="token punctuation">(</span>singsmaple<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token keyword">or</span> <span class="token builtin">max</span><span class="token punctuation">(</span>singsmaple<span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">1</span>ab_idxs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ii<span class="token punctuation">)</span>    idxs_saved <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>ab_idxs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ab_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>ab_idxs<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    save_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>idxs_saved<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    new_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>save_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    new_df <span class="token operator">=</span> new_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    abn_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>ab_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    abn_df <span class="token operator">=</span> abn_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> new_df<span class="token punctuation">,</span> abn_dfdf<span class="token punctuation">,</span> df_abn <span class="token operator">=</span> drop_abnormal_val<span class="token punctuation">(</span>df_src<span class="token punctuation">)</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/199510957-fff5206f-882e-4fb9-9047-7c599f03555d.png" alt="image"></p><p>这种方式，处理完所有样本所需时间为11分54秒，对于数据集处理来说，显得过于耗时。</p><h2 id="列扩增实现pandas运算"><a href="#列扩增实现pandas运算" class="headerlink" title="列扩增实现pandas运算"></a>列扩增实现pandas运算</h2><p>注意到运算逻辑是需要计算每个样本的最大和最小值。利用pandas本身的计算最值算子，将计算出的最大、最小值作为新的列扩增到原来的dataframe中。那么仅需定位这两个最值列，即可定位到异常样本索引。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">drop_abnormal_val</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>    df<span class="token punctuation">[</span><span class="token string">'max_val'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    df<span class="token punctuation">[</span><span class="token string">'min_val'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    ab_idxs <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'min_val'</span><span class="token punctuation">]</span><span class="token operator">&lt;=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">|</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'max_val'</span><span class="token punctuation">]</span><span class="token operator">>=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>    idxs_saved <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>ab_idxs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ab_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>ab_idxs<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    save_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>idxs_saved<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    new_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>save_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    new_df <span class="token operator">=</span> new_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    abn_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>ab_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    abn_df <span class="token operator">=</span> abn_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> new_df<span class="token punctuation">,</span> abn_dfdf<span class="token punctuation">,</span> df_abn <span class="token operator">=</span> drop_abnormal_val<span class="token punctuation">(</span>df_src<span class="token punctuation">)</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/199510268-a2c6ed09-0fca-448f-b30b-141c11bd31b7.png" alt="image"></p><p>依据这种思想，可以看到完成同样处理逻辑，所需时间下降到41.7s!</p><h2 id="本身算子完成pandas运算"><a href="#本身算子完成pandas运算" class="headerlink" title="本身算子完成pandas运算"></a>本身算子完成pandas运算</h2><p>前面一种做法，显然产生了冗余数据，扩增的两列在后续业务处理时，还需要去掉。那么基于更简洁代码、更省存储资源的原则，直接针对原始多维特征进行条件判断；</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">drop_abnormal_val</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">:</span>        ab_idxs <span class="token operator">=</span> df<span class="token punctuation">.</span>index<span class="token punctuation">[</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span>spc_names<span class="token punctuation">]</span><span class="token operator">&lt;=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">|</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span>spc_names<span class="token punctuation">]</span><span class="token operator">>=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>    idxs_saved <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>ab_idxs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ab_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>ab_idxs<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    save_idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>        <span class="token string">"query_1"</span><span class="token punctuation">:</span>idxs_saved<span class="token punctuation">,</span>    <span class="token punctuation">&#125;</span>    new_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>save_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    new_df <span class="token operator">=</span> new_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    abn_df <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>ab_idx<span class="token punctuation">[</span><span class="token string">'query_1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    abn_df <span class="token operator">=</span> abn_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> new_df<span class="token punctuation">,</span> abn_dfdf<span class="token punctuation">,</span> df_abn <span class="token operator">=</span> drop_abnormal_val<span class="token punctuation">(</span>df_src<span class="token punctuation">)</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/199509946-415e6891-1138-4f32-b84c-098aa30befe8.png" alt="image"></p><p>速度下降到1.4s，相对于第一种方式提速了500多倍！！同样的数据，完成相同的目的。不同的方法实现的效率简直天壤之别！！！</p><p>另外，针对第2、3种方式，可以看到，使用<code>iloc</code>定位指定索引的样本时，采用了通过字典读取索引的方式，因为字典可以通过哈希表的方式加快读取速度。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>总体来说，提速思路从以下两个方面开展：</p><ul><li>要有改进代码的意识，输出结果不是最终目的，增加过程的体验很重要。</li><li>要尽可能使用语言本身的算子（内置函数），做到代码简洁。这些算子是这门语言的有用利器。</li></ul><p>另外，对于pandas运算，还有两个可以尝试的加速方向：一是使用numba，首先将dataframe转换为numpy数组的形式；二是通过cython，涉及到耗时的运算逻辑，采用c++来实现，通过cython实现python调用c++，从而实现提速。</p>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据科学/机器学习中如何应对超大型数据集的处理</title>
      <link href="/2022/10/22/how-to-handling-huge-dataset-in-data-science-or-machine-learning/"/>
      <url>/2022/10/22/how-to-handling-huge-dataset-in-data-science-or-machine-learning/</url>
      
        <content type="html"><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>在数据科学领域，python应当是目前最为常用的开发语言。由于数据分析、机器学习大部分时间基本在处理数据集，对于一般大小的数据文件，采用pandas读取基本已经足够。但若一个数据集大小达到1G甚至10G，pandas读取就显得效率太低，变得不再实用。</p><p>那么有哪些应对大数据集的提速处理方式呢？本文从以下两个角度说明几种提供数据处理速度的方式：</p><ul><li>相较pandas，python中提速方式</li><li>采用c++处理数据，实现提速</li></ul><h2 id="pandas-read-csv"><a href="#pandas-read-csv" class="headerlink" title="pandas read_csv"></a>pandas read_csv</h2><p>数据科学中，典型的结构化数据存储形式为csv格式，通常是用pandas来对其进行操作：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'data/df_data.csv'</span><span class="token punctuation">)</span>df_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/197244671-2ced6ca4-dfc4-401c-a011-f2a50a85fe54.png" alt="image"></p><p>一般情况下，我们所处理的单个csv文件大小不会超过100M。pandas基本可以较快地对其进行读取和操作。但当达到几个G的大小时，pandas直接处理就显得力不从心。速度慢是一方面，若文件太大，内存可能都无法读入全部的数据，比如下图所示：</p><p><img src="https://user-images.githubusercontent.com/114786693/197243918-46c060e3-87a2-4610-992c-fe1cc0b67d62.png" alt="image"></p><p>下面说明几种提速方式，并给出相应的用法。</p><h2 id="python-中的提速方式"><a href="#python-中的提速方式" class="headerlink" title="python 中的提速方式"></a>python 中的提速方式</h2><h3 id="pandas-read-csv的chunksize字段"><a href="#pandas-read-csv的chunksize字段" class="headerlink" title="pandas read_csv的chunksize字段"></a>pandas read_csv的<code>chunksize</code>字段</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">chunks <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'data/df_data.csv'</span><span class="token punctuation">,</span> chunksize<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span>df_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>chunks<span class="token punctuation">)</span>df_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/197245247-87bdab08-2ee2-42b4-8b1b-4eef65ed2503.png" alt="image"><br>可以看到，通过增加<code>chunksize</code>字段，读取时间反而有所上升。这是由于<code>chunksize</code>的大小影响了读取的速度，因此，要想通过这一字段提速，前提是能够选择合适大小的chunksize，否则反而对读取效率产生负面影响。</p><h3 id="pandas-read-csv的engine字段"><a href="#pandas-read-csv的engine字段" class="headerlink" title="pandas read_csv的engine字段"></a>pandas read_csv的<code>engine</code>字段</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">df_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'data/df_data.csv'</span><span class="token punctuation">,</span> engine<span class="token operator">=</span><span class="token string">'c'</span><span class="token punctuation">)</span>df_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/197245511-f0eceb7c-0341-463f-8bd2-7e776a47b8fc.png" alt="image"></p><p>可以看到，通过将读取csv的后端引擎更改为<code>C语言</code>，读取效率有明显提升。</p><h3 id="dask-dataframe"><a href="#dask-dataframe" class="headerlink" title="dask dataframe"></a>dask dataframe</h3><p>dask是由google主导开发的适用于大数据集的pandas替代方案。一直以来，spark在大数据分析领域占据主导领域，近年来，之前采用spark的用户也在开始切换到dask上来。另外，同时存在一些其他的处理方案，比如<a href="https://github.com/ray-project/ray">Ray</a>和<a href="https://github.com/vaexio/vaex">Vaex</a>。在使用覆盖面上，dask是被使用最多的，。Ray是由Berkeley主导开发的，Vaex主要是由荷兰的程序员和数据科学家开发的。初看各家发展生态，dask应当是更胜一筹。</p><p>dask本身主要存在两点优势：</p><ul><li>并行化：相较于pandas单核处理数据，dask可以进行多线程并行处理数据；</li><li>delayed计算：dask采用一种lazy的方式，对数据进行处理。所谓的lazy计算，是以仅保存计算流程图的方式，记录计算目标的计算流程。但并不执行计算本身。只有需要获取计算目标结果时，通过<code>compute()</code>来执行整个计算流程，获得输出结果。</li></ul><p>其用法如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> dask<span class="token punctuation">.</span>dataframe <span class="token keyword">as</span> dddata <span class="token operator">=</span> dd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r'data/output/df_data.csv'</span><span class="token punctuation">)</span>df_data <span class="token operator">=</span> data<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span>df_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://user-images.githubusercontent.com/114786693/197248556-14f341cc-08b8-45be-9493-2769fd5861ab.png" alt="image"></p><p>可以看到，相比于pandas直接读取，<a href="https://github.com/dask/dask">dask</a>读取整个数据集所需时间降低了1&#x2F;3，是提速表现最好的。</p><h2 id="通过c-进行数据处理提速"><a href="#通过c-进行数据处理提速" class="headerlink" title="通过c++进行数据处理提速"></a>通过c++进行数据处理提速</h2><p>前面我们看到，通过python处理一个数据集，将其保存到一个numpy array对象中，该对象大小达到9G。无法将其保存为dataframe对象写入到本地csv文件中，也无法通过numpy、pickle写入到本地。原因都是太占内存（MemoryError）。如果无法将其保存到本地，那么目标数据就无法持久化，也就降低了重复使用性。</p><p>既然无法直接通过python将该对象存储到本地文件中，此时想出了下面的解决办法：</p><ul><li>先将numpy array对象转换为list对象，然后通过python将该list对象写入到本地txt。出乎意料的是，python将这么大的对象写入到txt的速度出奇的快，9个G大小的list对象，写入到本地txt完成所花时间不到30s；<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">r'all_vals.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>    <span class="token keyword">for</span> item <span class="token keyword">in</span> contents<span class="token punctuation">:</span>        fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%s\n"</span> <span class="token operator">%</span> item<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>通过c++将该txt文件准换为csv文件。c++本身作为基础编程语言，在效率上一直是其最大的优势：<pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">string file_name <span class="token operator">=</span> <span class="token string">"all_vals.txt"</span><span class="token punctuation">;</span>string nfile_name <span class="token operator">=</span> <span class="token string">"all_vals.csv"</span><span class="token punctuation">;</span>ifstream <span class="token function">in</span><span class="token punctuation">(</span>file_name<span class="token punctuation">)</span><span class="token punctuation">;</span>string line<span class="token punctuation">;</span>ofstream textfile<span class="token punctuation">;</span>textfile<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>nfile_name<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">const</span> <span class="token keyword">char</span><span class="token operator">*</span> bom <span class="token operator">=</span> <span class="token string">"\xef\xbb\xbf"</span><span class="token punctuation">;</span> <span class="token comment">// 写入csv，需要加上bom头，否则写入中文乱码</span>textfile <span class="token operator">&lt;&lt;</span> bom<span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token function">getline</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// line中没有换行符</span><span class="token punctuation">&#123;</span>    string ss <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">substr</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>line<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>              textfile <span class="token operator">&lt;&lt;</span> ss <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>将2个多G的txt文件重新写入到csv文件，所需时间为5分钟左右。整体而言，通过转换思路，并借助于python之外的开发语言，使我们的数据开发效率得到很大的提升。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>在应对csv大数据集的读取上，采用dask能够显著提高效率，这也是最终我们采取的数据集处理方式</li><li>当涉及大数据集的读取写入时，可以采用c++来完成我们的数据准备工作。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据科学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> c++ </tag>
            
            <tag> csv </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于用pandas处理csv文件数据的一些事</title>
      <link href="/2022/10/13/stuffs-about-handling-csv-data-with-pandas/"/>
      <url>/2022/10/13/stuffs-about-handling-csv-data-with-pandas/</url>
      
        <content type="html"><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>在做数据分析或者机器学习工作时，很多情况会涉及对csv格式的处理分析。pandas作为数据科学的常用工具包，对于csv格式数据的处理已经相当成熟。从对过去几个项目中的处理过的csv格式数据总结来看，发现有两个普遍而关键的处理用法：</p><ul><li>关注读取csv获得的dataframe中，各列的数据类型；</li><li>如何快速对某个或者某个列进行数据变换。</li></ul><h2 id="变量数据类型"><a href="#变量数据类型" class="headerlink" title="变量数据类型"></a>变量数据类型</h2><p>当我们用pandas读取csv表格后，会获取到一个dataframe，首先需要检查dataframe所有列的数据类型，如下图所示：<br><img src="https://user-images.githubusercontent.com/114786693/195628141-6888b372-d636-482e-b2b6-cf6685066bb0.png" alt="image"><br>可以看到，最后两列数据类型为<code>object</code>。一旦出现这种情况，一定要将这些列准换为指定的数据类型。否则这些列的数据不能正常被读取到，会出现以下情况：<br><img src="https://user-images.githubusercontent.com/114786693/195629821-99968961-c619-42d7-a1a6-f5447bfd6c25.png" alt="image"><br>上图中，处理逻辑是获取目标变量列中指定元素的索引，当目标变量列数据类型为object时，由于<code>ll</code>为列表<code>class_range</code>中的元素，其为数值或者字符类型，判断两者相等有两层含义，一是数据类型相同，二是数值相等。然而两者数据类型不同，造成即使该列存在等于指定数值的元素，最后返回的索引仍为空。</p><p>因此，需要对各列进行数据类型转换，如下图所示：<br><img src="https://user-images.githubusercontent.com/114786693/195627568-fae5f39d-7f30-4b03-98fa-4f205f3f6cb1.png" alt="image"><br><img src="https://user-images.githubusercontent.com/114786693/195632156-88401f8e-f7b1-46ba-9460-64d964bc3575.png" alt="image"></p><p>只有完成了数据类型的转换，才能保证后续能够对获取到的dataframe进行正常处理。</p><h2 id="更改某个或者某些变量的值"><a href="#更改某个或者某些变量的值" class="headerlink" title="更改某个或者某些变量的值"></a>更改某个或者某些变量的值</h2><p>在dataframe处理过程中，经常需要对某个或者某些变量的数值进行同时处理，如下面两种情况：</p><ul><li>对某些列同时进行数据类型转换，如下图所示：<br><img src="https://user-images.githubusercontent.com/114786693/195627568-fae5f39d-7f30-4b03-98fa-4f205f3f6cb1.png" alt="image"><br>采用<code>apply()</code>函数实现。</li><li>对某一列的数值同时进行变换，如下所示：<pre class="line-numbers language-python" data-language="python"><code class="language-python">df<span class="token punctuation">[</span><span class="token string">"col1"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"col1"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x <span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>ll<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'_'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>这里采用<code>map()</code>函数实现，原因是针对单个column，map比apply更快。（解释来自<a href="https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas">stackoverflow</a>）</li></ul><h2 id="lambda用法"><a href="#lambda用法" class="headerlink" title="lambda用法"></a>lambda用法</h2><p>注意上面通过<code>lambda</code>关键字的用法，与MATLAB用法一致，用于定义匿名函数，同时应用于全部的输入。比如简单的函数：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">df<span class="token punctuation">[</span><span class="token string">"col"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"col"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x <span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里是将列名为“col”的全部数值转换为string类型。也可以定义复杂的匿名函数，比如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sel_encode</span><span class="token punctuation">(</span>code<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>    pref <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>code<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>code<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>        pref <span class="token operator">=</span> <span class="token string">'0'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>code<span class="token punctuation">)</span>    tail <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>        tail <span class="token operator">=</span> <span class="token string">'0'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">return</span> pref<span class="token operator">+</span><span class="token string">'_'</span><span class="token operator">+</span>taildf<span class="token punctuation">[</span><span class="token string">"col"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"col"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> sel_encode<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，定义了一个更加复杂的匿名函数，列名为“col”的全部数值应用该函数进行变换。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要是从两方面说明：</p><ul><li>针对通过pandas读取到的csv数据，首先需要确认各列的数据类型；</li><li>可以采用<code>apply()</code>或者<code>map()</code>函数，快速实现对dataframe中某一列或者某些列的数据变换；</li><li>通过<code>lambda</code>关键字自定义函数，使得全部输入同时应用该函数进行处理。</li></ul>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pandas </tag>
            
            <tag> csv </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>image labeling for supervised learning</title>
      <link href="/2022/10/11/image-labeling-for-supervised-learning/"/>
      <url>/2022/10/11/image-labeling-for-supervised-learning/</url>
      
        <content type="html"><![CDATA[<hr><p>监督学习下的建模过程，高质量的数据是构建好的模型的第一步。对于机器学习，包括了提取高质量的特征和标签的准确性；对于深度学习，则需确保标签的准确。</p><p>深度学习中的主要任务，包括分类、分割、检测，其首要任务均是对数据进行标注。分类是给样本标注类别标签，分割是给图像某个区域的所有像素点标注类别标签，检测是给图像中的目标，既标注类别标签，也标注目标的位置。数据标注过程的严谨性与标注结果的准确，决定了是否能够训练出更加优秀的模型。</p><p>关于如何提高对监督学习下的模型构建过程中的第一步——数据标注的工作质量，近期看了LandingAI的一篇post，给了较好的启发。</p><p>文章以缺陷检测为示例，总体从以下几个方面论述开来：</p><ul><li><p>数据标注的说明</p></li><li><p>图像检测项目中数据标注的挑战：主要包括两点，缺陷样本较少，不同业务专家对缺陷的理解不同。譬如下图所示：<br><img src="https://user-images.githubusercontent.com/114786693/195116140-c14f228e-7bb7-4c1f-a433-31adffc7b445.png" alt="image"></p></li><li><p>如何对不同达成共识：包括，缺陷说明书；机器学习（MLE）与业务专家（SME）对缺陷的定义一致；多个标注工程师同时对同一图像进行标注，选取达成一致的结果</p></li></ul><p>最终标注过程所期望的结果，是达成共识而且没有争议的结果。</p><br><p><strong>Reference</strong></p><p>[1] <a href="https://landing.ai/data-labeling-of-images-for-supervised-learning/">https://landing.ai/data-labeling-of-images-for-supervised-learning/</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据标注 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在visual studio 2022中构建opencv项目</title>
      <link href="/2022/10/10/build-opencv-project-in-visual-studio-2022/"/>
      <url>/2022/10/10/build-opencv-project-in-visual-studio-2022/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>由于c++中执行效率方面的优势，本身是作为一种底层语言，用于开发各种系统和应用，运行速度相比其他语言（如MATLAB、Python更加快速）。</p><p>opencv作为在图像处理领域最为广泛使用的开源库，功能丰富，执行效率高。本文在windows安装visual studio 2022(vs++) 搭建c&#x2F;c++开发环境，并安装opencv c++版本，使用c++基于opencv库开发图像处理项目。</p><h2 id="vs-安装"><a href="#vs-安装" class="headerlink" title="vs++安装"></a>vs++安装</h2><p>通过下载vs++ installer安装包，直接在本地安装c++开发IDE环境。</p><p>首先在<a href="https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false">此处</a> 下载安装包。</p><p>建立c++桌面开发程序的后续安装过程参考<a href="https://blog.csdn.net/InnerPeaceHQ/article/details/121716088">此文</a> 即可。</p><p>安装过程主要注意选择不同的功能集和工作负载，同时选择安装路径（建议使用默认安装路径）。在窗口的上方还有单个组件、语言包、安装位置这些选项，可以不用管，均为默认值。最后点击安装。</p><p>若后续由其他开发需求，可再次运行此installer，选择其他组件进行安装。</p><h2 id="opencv安装"><a href="#opencv安装" class="headerlink" title="opencv安装"></a>opencv安装</h2><p>由于之前一直使用的opencv-python版本为4.5.5.64，为了使两者尽可能保持一致。安装的opencv c++版本也为4.5.5。下载地址在<a href="https://github.com/opencv/opencv/releases/download/4.5.5/opencv-4.5.5-vc14_vc15.exe">此处</a>。</p><p>opencv的安装主要注意以下两点:</p><ul><li>将opencv添加到环境变量</li><li>设置项目的property，分别在vc++ directories和linker中添加代码源和动态链接库，如下图所示：<br> <img src="https://user-images.githubusercontent.com/114786693/194904623-b9733954-4f07-4b73-9ed7-2254e5ba68b5.png" alt="image"><br> <img src="https://user-images.githubusercontent.com/114786693/194904382-1a28aacf-28a0-461d-b47a-8deb288345d4.png" alt="image"></li></ul><h2 id="示例程序结果"><a href="#示例程序结果" class="headerlink" title="示例程序结果"></a>示例程序结果</h2><p>写了一个opencv读取图像的示例，执行结果如下图所示：<br><img src="https://user-images.githubusercontent.com/114786693/194894601-bd87c02a-f05c-4c15-80f7-b9f4b89821fa.png" alt="image"></p><p>可以看到，成功输出图像结果。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文获得了以下两个成果：</p><ul><li>成功构建了c++开发环境；</li><li>可基于opencv c++开发图像处理应用。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vs++ </tag>
            
            <tag> opencv </tag>
            
            <tag> c++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmsegmentation图像分割模型推理grpc调用服务，并通过bat脚本一键部署到新环境</title>
      <link href="/2022/10/07/mmseg-grpc-service-one-key-deploy-with-windows-batch-script/"/>
      <url>/2022/10/07/mmseg-grpc-service-one-key-deploy-with-windows-batch-script/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="背景说明"><a href="#背景说明" class="headerlink" title="背景说明"></a>背景说明</h2><p>采用mmsegmentation对标注好的训练集图像进行训练，得到最终训练好的图像分割深度学习模型。为了将训练好的模型部署到应用环境，以实现模型推理，并进一步将推理结果用于后续业务分析。本项目从以下三个步骤来完成该项目目的：</p><ul><li>调用训练好的模型，编写业务处理代码，实现推理结果的进一步分析；</li><li>grpc服务搭建，实现跨平台、跨语言的项目服务调用；</li><li>编写windows批处理脚本实现新环境的一键部署。</li></ul><h2 id="模型调用，业务代码编写"><a href="#模型调用，业务代码编写" class="headerlink" title="模型调用，业务代码编写"></a>模型调用，业务代码编写</h2><p>由于模型是采用mmseg进行训练的，调用仍采用mmseg相应的模型调用接口，以实现模型的调用。</p><p>针对模型的推理输出，编写业务代码，实现对推理结果进一步的业务处理。</p><h2 id="grpc服务搭建"><a href="#grpc服务搭建" class="headerlink" title="grpc服务搭建"></a>grpc服务搭建</h2><p>由于模型的调用服务代码均是在windowns平台采用python编写，为了使其能够满足跨平台、跨语言的服务调用，我们采用grpc搭建模型调用服务，使用protobuf对传输数据、请求数据以及响应数据进行定义。下面是本项目所定义的消息结构：</p><pre class="line-numbers language-protobuf" data-language="protobuf"><code class="language-protobuf"><span class="token keyword">syntax</span> <span class="token operator">=</span> <span class="token string">"proto3"</span><span class="token punctuation">;</span><span class="token keyword">message</span> <span class="token class-name">ABImage</span> <span class="token punctuation">&#123;</span>    <span class="token builtin">bytes</span> data <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>   <span class="token comment">// 图像字节</span>    <span class="token builtin">int32</span> width <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>  <span class="token comment">// 图像宽度</span>    <span class="token builtin">int32</span> height <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span> <span class="token comment">// 图像高度</span><span class="token punctuation">&#125;</span><span class="token comment">// 请求的参数</span><span class="token keyword">message</span> <span class="token class-name">PredictRequest</span><span class="token punctuation">&#123;</span>    <span class="token builtin">string</span> model_path <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token comment">// 模型所在路径</span>    <span class="token builtin">string</span> config_path <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span> <span class="token comment">// 模型配置文件所在路径</span>    <span class="token builtin">string</span> img_path <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>    <span class="token comment">// 输入图像路径， 用于模型推理</span>    <span class="token builtin">string</span> redun_id <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>    <span class="token comment">// 冗余输入头，标记</span><span class="token punctuation">&#125;</span><span class="token comment">// 定义返回的参数</span><span class="token keyword">message</span> <span class="token class-name">PredictRespense</span><span class="token punctuation">&#123;</span>    <span class="token builtin">string</span> redun_id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>    <span class="token builtin">bool</span> is_error <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>    <span class="token builtin">string</span> error_message <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>    <span class="token builtin">float</span> res_g_ratio <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>    <span class="token builtin">float</span> res_y_ratio <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>    <span class="token positional-class-name class-name">ABImage</span> image <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token comment">// 定义服务接口</span><span class="token keyword">service</span> <span class="token class-name">Predictor</span><span class="token punctuation">&#123;</span>    <span class="token keyword">rpc</span> <span class="token function">predict</span><span class="token punctuation">(</span><span class="token class-name">PredictRequest</span><span class="token punctuation">)</span> <span class="token keyword">returns</span> <span class="token punctuation">(</span><span class="token class-name">PredictRespense</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从定义的消息结构可看到，服务调用过程既可传输数值或者字符串型结果，也可传输图像结果。</p><h2 id="windows批处理脚本一键部署"><a href="#windows批处理脚本一键部署" class="headerlink" title="windows批处理脚本一键部署"></a>windows批处理脚本一键部署</h2><p>要将在开发环境编写完成的项目服务代码，部署到新环境中，需要解决以下几个问题：</p><ul><li>项目所需的软件安装包；</li><li>项目的依赖包；</li><li>服务的开启。</li></ul><p>为了提高项目在新环境的服务部署效率，编写了一键部署脚本，仅需执行此脚本即可完成服务的部署和开启。</p><p>本项目所编写的batch脚本：</p><pre class="line-numbers language-bat" data-language="bat"><code class="language-bat">::-- Script to automate deploy deep learning model inferiing service to new environmenrt.@REM 一键部署项目执行环境。使用方法：@REM  - 1.手动安装anaconda安装包，直接next下去，直到安装完成。（注意有一步需要将其添加到环境变量）@REM  - 2.在项目目录下打开anaconda窗口，在命令行输入脚本执行命令：.\easy_deploy.bat（windows批处理脚本）@REM 优点在于，即可以执行DOS命令，也可以执行python环境命令echo &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;开始部署&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;:: 1、配置anaconda的python执行环境:: 根据conda安装地址相应修改set CONDAPATH&#x3D;D:\ProgramData\Anacondacall %CONDAPATH%\Scripts\activate.bat %CONDAPATH%:: 2、配置国内源，提高下载速度call conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free&#x2F;call conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main&#x2F;pip config set global.index-url https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple:: 3、安装项目依赖包pip install numpy terminaltables matplotlib tqdm pandas timm Pillow grpcio&#x3D;&#x3D;1.49.0 protobuf&#x3D;&#x3D;4.21.7 opencv_python_headless&#x3D;&#x3D;4.5.5.64pip install torch&#x3D;&#x3D;1.10.0+cpu torchvision&#x3D;&#x3D;0.11.0+cpu torchaudio&#x3D;&#x3D;0.10.0 -f https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;torch_stable.htmlpip install mmcv-full&#x3D;&#x3D;1.5.0 -f https:&#x2F;&#x2F;download.openmmlab.com&#x2F;mmcv&#x2F;dist&#x2F;cpu&#x2F;torch1.10.0&#x2F;index.htmlecho &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;依赖包下载完成！&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;:: 4、开启grpc服务端python dl_server.pyecho &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;服务启动完成！&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，该脚本可实现环境的配置、依赖包的下载以及服务的开启。需要注意的地方是，在调用每一个conda命令时，要在调用命令前加上<code>call</code>，否则脚本执行完该conda语句就会结束。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本项目实现了以下三个主要功能：</p><ul><li>深度学习模型的调用推理；</li><li>grpc服务的搭建，实现跨平台、跨语言的服务搭建；</li><li>提供批处理脚本，实现项目服务在新环境的部署与开启。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> mmsegmentation </tag>
            
            <tag> grpc </tag>
            
            <tag> batch script </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo博客撰写与发表</title>
      <link href="/2022/10/03/hexo-post-deploy/"/>
      <url>/2022/10/03/hexo-post-deploy/</url>
      
        <content type="html"><![CDATA[<h2 id="write-new-post-and-deploy-to-github"><a href="#write-new-post-and-deploy-to-github" class="headerlink" title="write new post and deploy to github"></a>write new post and deploy to github</h2><ol><li><p>Create new post</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token variable">$hexo</span> new <span class="token string">"title"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Deploy to github</p></li></ol><ul><li>update message in <code>_config.yml</code></li><li>execute the following hexo commands in bash   <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token variable">$hexo</span> clean <span class="token operator">&amp;&amp;</span> hexo g<span class="token variable">$hexo</span> server<span class="token variable">$hexo</span> deploy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="Post-font-header定义"><a href="#Post-font-header定义" class="headerlink" title="Post font-header定义"></a>Post font-header定义</h2><h3 id="Detailed-Front-matter-options"><a href="#Detailed-Front-matter-options" class="headerlink" title="Detailed Front-matter options"></a>Detailed Front-matter options</h3><p>Everything in the Front-matter option is <strong>not required</strong>. But I still recommend at least filling in the values of <code>title</code> and <code>date</code>.</p><table><thead><tr><th>Options</th><th>Defaults</th><th>Description</th></tr></thead><tbody><tr><td>title</td><td>Markdown’s file title</td><td>Post title, it is highly recommended to fill in this option</td></tr><tr><td>date</td><td>Date and time when the file created</td><td>Publish time, it is highly recommended to fill in this option, and it is best to ensure that it is globally unique</td></tr><tr><td>author</td><td><code>author</code> in root <code>_config.yml</code></td><td>Post author</td></tr><tr><td>img</td><td>a value in <code>featureImages</code></td><td>Post feature image，For example: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>Recommended post (whether the post is topped), if the <code>top</code> value is <code>true</code>, it will be recommended as a homepage post.</td></tr><tr><td>hide</td><td><code>false</code></td><td>Whether show this post in homepage, if the <code>hide</code> value is <code>true</code>, it will not be showed in homepage.</td></tr><tr><td>cover</td><td><code>false</code></td><td>The <code>v1.0.2</code> version is added to indicate whether the post needs to be added to the homepage carousel cover.</td></tr><tr><td>coverImg</td><td>null</td><td>The new version of <code>v1.0.2</code> indicates that the post needs to display the image path on the cover of the homepage. If not, the default image of the post is used by default.</td></tr><tr><td>password</td><td>null</td><td>The post read the password. If you want to set the reading verification password for the article, you can set the value of <code>password</code>, which must be encrypted with <code>SHA256</code> to prevent others from seeing it. The premise is that the <code>verifyPassword</code> option is activated in the theme’s <code>config.yml</code></td></tr><tr><td>toc</td><td><code>true</code></td><td>Whether TOC is turned on or not, you can turn off the TOC function for an article. The premise is that the <code>toc</code> option is activated in the theme’s <code>config.yml</code></td></tr><tr><td>mathjax</td><td><code>false</code></td><td>Whether to enable math formula support, whether this article starts <code>mathjax</code>, and you need to open it in the theme <code>_config.yml</code> file.</td></tr><tr><td>summary</td><td>null</td><td>Post summary, custom post summary content, if the attribute has a value, the post card summary will display the text, otherwise the program will automatically intercept part of the article as a summary</td></tr><tr><td>categories</td><td>null</td><td>Article classification, the classification of this topic represents a macroscopically large classification, only one article is recommended for one classification.</td></tr><tr><td>tags</td><td>null</td><td>Post label, a post can have multiple labels</td></tr><tr><td>keywords</td><td>Post Title</td><td>Post key Words With SEO</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>Post reprint policy, value could be one of cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint and pay</td></tr></tbody></table><blockquote><p><strong>Note</strong>: </p><ol><li>post’s featured picture will take remainder if not writing the <code>img</code> property, and choose the featured picture of theme to let all of post’s picture <strong>have their own characteristics</strong>.</li><li>The value of <code>date</code> should try to ensure that each article is unique, because <code>Gitalk</code> and <code>Gitment</code> recognize <code>id</code> in this topic are uniquely identified by the value of <code>date</code>.</li><li>If you want to set the ability to read the verification password for the article, you should not only set the value of the password with SHA256 encryption in Front-matter, but also activate the configuration in the theme <code>_config.yml</code>.</li><li>you can define reprint policy for a single article in the front-matter of the specific md file using this key: reprintPolicy</li></ol></blockquote><p>The following are examples of the post’s <code>Front-matter</code>.</p><h3 id="The-simplest-example"><a href="#The-simplest-example" class="headerlink" title="The simplest example"></a>The simplest example</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme Theme introduction<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="The-most-comprehensive-example"><a href="#The-most-comprehensive-example" class="headerlink" title="The most comprehensive example"></a>The most comprehensive example</h3><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme Theme introduction<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> Qi Zhao<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">hide</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> This is the content of your custom post summary. If there is a value for this attribute<span class="token punctuation">,</span> the post card summary will display the text<span class="token punctuation">,</span> otherwise the program will automatically intercept part of the post content as a summary.<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown<span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>封控期间的菜单</title>
      <link href="/2022/06/01/my-menu-during-shanghai-s-lockdown/"/>
      <url>/2022/06/01/my-menu-during-shanghai-s-lockdown/</url>
      
        <content type="html"><![CDATA[<p>上海在春天的时光里，封控两个多月，而我练就了一手好饭。</p><ul><li>3.14 鲫鱼+煎豆腐、青椒+鸡蛋</li><li>3.15 红烧肉、番茄+鸡蛋；胡萝卜、杏鲍菇</li><li>3.16 鸡翅；胡萝卜、杏鲍菇</li><li>3.26 胡萝卜、黑木耳+花菜</li><li>3.27 茄子+青椒、青椒+鸡蛋</li><li>3.28 茄子+青椒、木耳+花菜</li><li>3.29 胡萝卜+黑木耳+娃娃菜；水饺+鸡蛋</li><li>3.30 番茄+鸡蛋、小青菜；水饺</li><li>3.31 </li><li>4.1  小青菜</li><li>4.3  牛肉、小青菜</li><li>4.4  牛肉、小青菜</li><li>4.5  胡萝卜、小青菜、鸡蛋</li><li>4.6  小青菜、鸡腿</li><li>4.7  面条+鸡蛋+小青菜</li><li>4.8  白萝卜+香菇、小青菜</li><li>4.9  面条+猪肉；鸡腿、番茄+鸡蛋</li><li>4.10 鸡肉+胡萝卜</li><li>4.11 拌面+鸡蛋</li><li>4.12 红烧肉、红烧白萝卜</li><li>4.13 小青菜、西葫芦、黄瓜</li><li>4.14 小青菜、西葫芦+胡萝卜+香肠、土豆</li><li>4.15 猪肉+娃娃菜+白萝卜+粉条+香菇、</li><li>4.16 白萝卜+胡萝卜、青椒+土豆；鸡蛋+香肠+泡面</li><li>4.17 面条+火腿+鸡蛋；猪肉+香菇+娃娃菜+粉条+剩饭；粽子</li><li>4.18 蛋炒饭；黄瓜、小青菜</li><li>4.19 面条+娃娃菜；土豆、包菜+胡萝卜</li><li>4.20 面包、牛奶；青菜、西葫芦、白萝卜；蛋糕</li><li>4.21 面条、鸡蛋+火腿、青菜；咖啡；土豆丝、西葫芦、白萝卜；白木耳+红枣+牛奶</li><li>4.22 面条、鸡蛋+火腿、青菜；土豆片、酱鸭</li><li>4.23 猪肉+娃娃菜+白萝卜+粉条+香菇+火腿、粽子、咖啡</li><li>4.24 黄瓜、小青菜、火腿+鸡蛋</li><li>4.25 椰子、咸蛋+粥</li><li>4.26 胡萝卜+土豆+咸肉；白木耳+红枣+牛奶</li><li>4.27 胡萝卜+土豆+咸肉；白木耳+红枣</li><li>4.28 面条+冬阴功；咸肉+青椒、火腿+鸡蛋</li><li>4.29 泡面+鸡蛋；意面+粽子；泡面+鸡蛋+火腿</li><li>4.30 鸡肉饭+鸡蛋；炒饭+鸡蛋+腊肠；牛奶</li><li>5.1 炒饭+鸡蛋+火腿；黄瓜+胡萝卜+火腿；白木耳+红枣、泡面+火腿+鸡蛋</li><li>5.2 粉条+面条+小白菜+香菇、粽子白木耳+红枣；</li><li>5.3 面条+鸡蛋；腊肠+鸡蛋+青椒、胡萝卜、黄瓜；泡面+香菇+鸡蛋</li><li>5.4 面条+鸡蛋；、粥+火腿+香菇、腊肠+鸡蛋</li><li>5.5 面条+鸡蛋+小白菜；粥+小白菜、腊肠+鸡蛋+香菇；牛奶</li><li>5.6 鸡蛋；粥+小白菜+腊肉、鸡蛋+香菇；黑木耳</li><li>5.7 面条+鸡蛋；鸡蛋+饺子；黑木耳</li><li>5.8 面疙瘩、鸡蛋+火腿；烙饼+蚕豆+黑木耳</li><li>5.9 面条+小白菜+鸡蛋；烙饼+土豆+午餐肉；白木耳+红枣</li><li>5.10 面条+小白菜、鸡蛋+火腿+小青菜；咸肉+包菜、南瓜</li><li>5.11 面条+鸡蛋；包菜+粉丝+鸡蛋、土豆；海底捞</li><li>5.12 面条+鸡蛋；粥+绿豆、西葫芦、包菜;泡面+鸡蛋+香菇</li><li>5.13 面粉+鸡蛋；黑米、西葫芦+火腿+咸肉、黄豆</li><li>5.14 面条+鸡蛋+小青菜；焖饭+腊肠+土豆+咸肉+香菇、猪肉+黑木耳</li><li>5.15 面条+鸡蛋；包菜+洋葱、土豆；面疙瘩</li><li>5.16 黑米、咸肉+包菜、煎鸡蛋；煎饼+黑木耳+香菇</li><li>5.17 面条+鸡蛋；黑米、土豆、小青菜+香菇+黑木耳；绿豆汤</li><li>5.18 全家快餐；香菇+拌面+鸡蛋；绿豆汤；牛奶</li><li>5.19 黑米、包菜+咸肉+洋葱；牛奶</li><li>5.20 面疙瘩+鸡蛋；胡萝卜、青菜+香菇+火腿；拌面+香菇+黑木耳</li><li>5.21 烙饼；土豆、芹菜+火腿+木耳；热干面、拍黄瓜</li><li>5.22 芹菜+火腿+香菇+木耳、紫菜蛋花汤；烙饼</li><li>5.23 热干面、鸡蛋；包菜、黄瓜、火腿、紫菜蛋花汤</li></ul><p>3月下旬开始了封控，到6月1号正式解封。期间，居家办公，几乎每天的疫情志愿者服务，然后自己做饭。忙碌而幸福。</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 年代记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
